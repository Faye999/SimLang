{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Language 14, From individual to population (lecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This is a first draft of lecture notes for the Simulating Language course. It probably contains lots of typos!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the right questions to ask about learning?\n",
    "\n",
    "So far, we've considered two types of learner in this course: the Hebbian learner, which increases connection strength between co-active meaning and signal nodes; and the lateral inhibition learner, which does the same but also decreases connection weights between an active signal node and inactive meaning nodes, and between an active meaning node and inactive signal nodes. We can think of lateral inhibition as not only caring about the meaning-signal pair that was observed but also the *wrong* meanings and the *wrong* signals.\n",
    "\n",
    "These two types of learning are far from the only conceivable ways you could change the weights in a simple associative network. Assuming each weight is either increased by one, left the same, or decreased by one, there are actually 81 different possible weight update rules, of which Hebbian and lateral inhibition are only two. [Smith (2002)](https://www.tandfonline.com/doi/abs/10.1080/09540090210164306) looks exhaustively at all 81 different possible weight update rules and considers their influence on the way language evolves.\n",
    "\n",
    "When faced with a particular kind of learner, the most obvious question to ask is something like: **can this learner acquire an optimal language?** In a sense, this kind of question is behind a lot of theoretical development in linguistics. [Chomsky (1965)](https://wikipedia.org/wiki/Aspects_of_the_Theory_of_Syntax) proposed a *Language Acquisition Device* as part of human biology with the idea that this device must enable children to acquire the language spoken around them from example utterances that they are exposed to. A theory of language, Chomsky's terms, is *explanatorily adequate* if it sets out a model of a language acquisition device that could in principle acquire any of the world's languages in this way.\n",
    "\n",
    "\n",
    "### The \"acquisition test\"\n",
    "\n",
    "So, given an optimal language, can the Hebbian and Lateral Inhibition learners both acquire that language?\n",
    "\n",
    "We've already seen the answer to this, but let's review it: Given an optimal language, the Hebbian learner seems to be able to recall its training data well. For example, with one example for each meaning of a language that maps $m_1\\rightarrow s_1, m_2\\rightarrow s_2, m_3\\rightarrow s_3$, the resulting matrix is:\n",
    "\n",
    "\n",
    "|.    |$s_1$|$s_2$|$s_3$|\n",
    "|-----|-----|-----|-----|\n",
    "|$m_1$|1    |0    |0    |\n",
    "|$m_2$|0    |1    |0    |\n",
    "|$m_3$|0    |0    |1    |\n",
    "\n",
    "This gives the output: $m_1\\rightarrow s_1, m_2\\rightarrow s_2, m_3\\rightarrow s_3$\n",
    "\n",
    "\n",
    "Similarly, given the same optimal language, the Lateral Inhibition learner seems to be able to recall its training data well too. \n",
    "\n",
    "\n",
    "|.    |$s_1$|$s_2$|$s_3$|\n",
    "|-----|-----|-----|-----|\n",
    "|$m_1$|1    |-3   |-3   |\n",
    "|$m_2$|-3   |1    |-3   |\n",
    "|$m_3$|-3   |-3   |-3   |\n",
    "\n",
    "This also gives the output: $m_1\\rightarrow s_1, m_2\\rightarrow s_2, m_3\\rightarrow s_3$\n",
    "\n",
    "So, both learners pass the acquisition test just fine. If learning a language was all we cared about, then we'd have nothing more to say. Both models are explanatorily adequate. But this fails to address the question of where the language comes from in the first place. This is why we implemented a model of cultural evolution where we can see what a *population* of learners will do to a language as it is passed on through iterated learning. [Smith (2002)](https://www.tandfonline.com/doi/abs/10.1080/09540090210164306) proposed an additional \"construction test\": **can a population of learners construct an optimal language starting from a sub-optimal one?**\n",
    "\n",
    "### The \"construction test\"\n",
    "\n",
    "If we run a series of simulations with Hebbian and Lateral Inhbition learners, starting with random languages (with three meanings and three signals) we get results that look like this:\n",
    "\n",
    "![img](img/construction1.png)\n",
    "\n",
    "This graph shows the change in communicative accuracy over 500 generations in 100 simulation runs for each type of learner. There are 5 meanings and 5 signals in the languages and 100 agents in the population, with one agent being replaced every generation by a new learner, who is exposed to 100 utterances from randomly picked members of the population. The average communicative accuracy score is also plotted for both types of learner, demonstrating that Hebbian learners fail to reliably construct optimal languages, but Lateral Inhbition learners do.\n",
    "\n",
    "To summarise:\n",
    "\n",
    "- Hebbian learners: pass the acquisition test but do not construct\n",
    "\n",
    "- Lateral inhibition learners: pass the acquisition test and do construct\n",
    "\n",
    "The most important point for this course is that the difference here is only visible at the population level (and after cultural evolution has taken its course). The lesson is that there is a risk that by focussing solely on the individual level we will fail to spot important differences between different theories of how humans acquire language.\n",
    "\n",
    "## Bias\n",
    "\n",
    "Different weight update rules come with different biases, although these may not be revealed if we just look at the acqusition test. What's happening in the iterated learning simulations that we've been running is that the population's language (in this case, a vocabulary) **evolves to fit these biases**. We're going to talk about this idea in a lot more detail later in the course, but it's worth starting to think about it a bit here. This process of cultural evolution is different from the biological evolution we modelled in the first part of the course. Rather than focussing on the way in which our cognitive system evolves to be better at doing signalling, we're now looking at how signalling evolves to be better passed on by us! All the agents in the simulations plotted above have been identical at birth, so there is no biological evolution at all. Any changes that happen are due to the culture changing, and the only thing that is driving those changes is the nature of the individuals' learning biases. We can think of the learning machinery of the agents as being the environment that the (culturally) evolving signalling systems have to adapt to as they are passed from one generation to the next.\n",
    "\n",
    "Let's revist what the actual biases are for the Hebbian and Lateral Inhibition learners again so we can see why the culture evolves in the way it does.\n",
    "\n",
    "It's clearest if we look at what happens after a single exposure to one meaning paired with one signal. In the Lateral Inhibition case, we would have the following after $m_1\\rightarrow s_1$:\n",
    "\n",
    "\n",
    "|.    |$s_1$|$s_2$|$s_3$|\n",
    "|-----|-----|-----|-----|\n",
    "|$m_1$|1    |-1   |-1   |\n",
    "|$m_2$|-1   |0    |0    |\n",
    "|$m_3$|-1   |0    |0    |\n",
    "\n",
    "For $m_1$, this learner would then go on to produce $s_1$, and crucially, never $s_2$ or $s_3$. This means that the learner is biased *against* synonyms, because the weight change for the co-active meaning and signal (1) is greater than the weight change for the active meaning paired with the inactive signals (-1).\n",
    "\n",
    "For $m_2$ and $m_3$, this learner would produces either $s_2$ or $s_3$ but never $s_1$. This means that this learner is also biased against homonyms, because the weight change for an active signal paired with an inactive meaning (-1) is less than the weight change for an inactive signal and an inactive meaning (0).\n",
    "\n",
    "Comparing this with the Hebbian learner:\n",
    "\n",
    "|.    |$s_1$|$s_2$|$s_3$|\n",
    "|-----|-----|-----|-----|\n",
    "|$m_1$|1    |0    |0    |\n",
    "|$m_2$|0    |0    |0    |\n",
    "|$m_3$|0    |0    |0    |\n",
    "\n",
    "Like the lateral inhibition learner, for $m_1$, the Hebbian learner would then go on to produce $s_1$, and never $s_2$ or $s_3$. So, this learner too is biased *against* synonyms.\n",
    "\n",
    "However, For $m_2$ and $m_3$, this learner would produces either $s_1$, $s_2$ or $s_3$. This means that this learner is neutral with respect to homonyms.\n",
    "\n",
    "Smith (2002) shows that learners who can construct optimal languages in a population (like the lateral inhibition learner) are biased in favour of *one-to-one* mappings between meanings and signals. They disprefer homonymy and synonymy.\n",
    "\n",
    "One-to-one systems happen to be optimal for communication, and this is what emerges through the process of iterated learning in a population of learners with this kind of bias.\n",
    "\n",
    "## Are humans constructors?\n",
    "\n",
    "Our work with the simulations above suggests that, since we actually are able to communicate with language successfully (and if don't assume that language is somehow bestowed upon us by some divine entity), then populations of humans must be able to construct languages. This suggests that we too must have the right kind of constructor bias.\n",
    "\n",
    "There is some experimental evidence that children do indeed have this kind of anti-synonymy and anti-homonymy bias in word learning. For example, [Markman and Wachtel (1988)](https://www.sciencedirect.com/science/article/pii/0010028588900175?via%3Dihub) run an experiment in which children are shown an unfamiliar object and a familiar object and given an unfamiliar word:\n",
    "\n",
    "![img](img/fendle.png)\n",
    "\n",
    "In this context, children tend to pick the unfamiliar object. In other words, they would prefer that this new label not be paired with the object that they already have a label for. This is direct evidence for a learning bias against synonymy.\n",
    "\n",
    "What about homonymy? [Doherty (2004)](https://www.cambridge.org/core/journals/journal-of-child-language/article/childrens-difficulty-in-learning-homonyms/D04C8AE599C4A8F6634F40502E35D9CD) constructed a clever experiment to test this. He set up a scenario in which children were given strong expectations about what an unfamiliar word might refer to. For example, a story about a zoo visit that ends: \"... at the zoo, they saw a strange tapir from Brazil. Hamish thought the tapir's long nose looked funny.\" Then they were given a picture of a tapir and a familiar object (e.g. a cake) to see which one they thought was the tapir:\n",
    "\n",
    "![img](img/tapir1.png)\n",
    "\n",
    "In this context, they behaved as in the previous experiment, and in line with the setup in the story and picked the picture of the tapir.\n",
    "\n",
    "Crucially, however, Doherty then went on to change the story to one involving a familiar word: \"... at the zoo, they saw a strange cake from Brazil. Hamish thought the cake's long nose looked funny.\"\n",
    "\n",
    "![img](img/tapir2.png)\n",
    "\n",
    "Intriguingly, the children now preferred to pick the picture of the cake, even though the story strongly set up the expectation that this word should also refer to a strange zoo animal with a long nose.\n",
    "\n",
    "What this means is that children would prefer to reject the notion that the word \"cake\" can have more than one meaning, referring both to a cake and an unfamiliar animal. In other words, children also have an anti-homonomy bias.\n",
    "\n",
    "These experiments suggest that humans do indeed have the same bias as constructors in our model. They prefer one-to-one mappings. So, human vocabularies will tend to evolve to fit this bias, resulting in optimal communication purely through the process of iterated learning in a population.\n",
    "\n",
    "## But where do these biases come from?\n",
    "\n",
    "These results suggest that humans are born with the right kind of biases to enable construction of an optimal communication system through cultural evolution. But really, this just pushes the explanation back a step. In a search for an explanation of the evolution of human language we could rightly now demand an answer to the question: \"why are humans born with these biases?\". Note that this question is one about a different kind of innateness than we looked at in the first part of this course. There we were interested in the origins of genes that give rise directly to a signalling system directly, but now we'll looking to understand the origins of genes that give rise to a learning bias that influences the way in which signalling systems evolve culturally. This kind of innateness is the one set out in [Chomsky's (1965)](https://faculty.georgetown.edu/irvinem/theory/Chomsky-Aspects-excerpt.pdf) hypothesis of a Language Acquisition Device (LAD) that children use to acquire their language. (Although proponents of the Chomskyan view do not typically see an explantory role for cultural evolution in the actual emergence of the universal properties of language that the LAD purports to explain).\n",
    "\n",
    "So, a more satisfying account of the emergence of optimal signalling should not only account for how individual learning biases shape the cultural evolution of languages but also the way those biases themselves evolve biologically. Hopefully by now you are open to the notion that we should not expect biological evolution to necessarily provide us with the best of all possible worlds, and as a result we should not be satified with an explanation like: optimal languages are good, so obviously natural selection will lead to humans having the right kind of biases to give us optimal languages. In a case like this, we really need a model in order to be sure that we aren't missing any hidden problems with this theory.\n",
    "\n",
    "Our model would add genes to our agents that specify the learning rule that those agents would be born with. These genes would be inhereted from the agents' parents in the normal way, but in addition the agents would learn their language, which would be passed on *culturally* by iterated learning. Parents would be selected to create offspring depending on their ability to communicate.\n",
    "\n",
    "It would be a relatively straightforward hybrid of the models we have already built to do the simulations required. However, for reasons of space in this course, we won't explore it directly. However, luckily, [Smith (2004)](http://www.lel.ed.ac.uk/~kenny/publications/smith_04_evolution.pdf) did build just such a model. What Smith did was play a variety of learning rules off one another to see which types took over which others. In particular, he looked at lateral inhibition learners and Hebbian learners.\n",
    "\n",
    "He created a population mainly made up of one type, but with a small number of another type (which we can think of as the \"mutant\"). Agents inherit both the communication system (by cultural transmission) and their learning bias (by genetic transmission). This means that both culture and biology co-evolve simultaneouly. Smith asks the question, if selection is based on mutual communicative success, which mutants will invade? In particular, will lateral inhibition mutants invade a population of hebbian learners?\n",
    "\n",
    "### Evolution is hard\n",
    "\n",
    "Surprisingly, lateral inhibition learners don't often invade, *even though it would increase the fitness of the population if they did*. There appear to be two problems that evolution by natural selection finds it hard to solve in this situation.\n",
    "\n",
    "Firstly, you need a lot of mutants before they start to have a good effect on the population. A small number of lateral inhibition learners do not appear to sufficiently shift the type of language that the population speaks. In the early stages of an attempted invasion, the majority of the population has biases that do not disfavour homonymy, and a small number of lateral inhibition learners is not sufficient to wipe it out on its own.\n",
    "\n",
    "Secondly, just as we did with the model of the evolution of innate signalling, we have to ask *who benefits*? Smith ran his simulation with mututal benefit, so we might expect there to be no problem of this kind, but the issue in this co-evolutionary model is actually a bit more tricky. If an agent is born with a lateral inhibition bias and shifts the behaviour of the population towards better signalling, they simply aren't going to see the fruits of their contribution to the evolving language. This is because there is a time delay in cultural evolution. We may need multiple generations for the effect of learning biases to be revealed, so natural selection can at best \"reward\" your distant future ancestors but not you yourself.\n",
    "\n",
    "Now, there *may* be solutions to these two problems (for example, one could wonder what would happen in populations with spatial structure), but a reasonable conclusion is that it isn't straightforward to say that human learning biases have evolved for communication. This leaves us with some doubt perhaps that it is learning bias that is the explanatory engine driving languages towards optimal signalling.\n",
    "\n",
    "## An alternative: communicative rationality\n",
    "\n",
    "In the last lecture we discussed an alternative to saying that language is optimal because learners favour one-to-one languages. Instead of relying on learning bias to shift the population's language, perhaps speakers themselves choose signals *rationally* to optimise the likelihood that they will be understood by a listener who is like them. This intuition is the core of the \"rational speech act\" theory of pragmatics ([Goodman & Frank, 2016](https://www.sciencedirect.com/science/article/pii/S136466131630122X?via%3Dihub)) which makes good predictions about how speakers and listeners behave in cases where the literal meaning of an utterance is not the one typically chosen. Whereas the full rational speech act theory considers rationality in both speakers *and* listeners, our simplified version just assumes that speakers will \"notice\" when they are about to say something ambiguous and try a random signal instead. Although this is not a particularly clever strategy, since it doesn't take into account the listener beyond the very first step, it nevertheless has a suprisingly striking effect on the cultural evolution of language, even with Hebbian learners.\n",
    "\n",
    "![img](img/construction2.png)\n",
    "\n",
    "As in the earlier figure, this graph shows the change in communicative accuracy over 500 generations in 100 simulation runs, but this time for a non-rational Hebbian learner, and a rational Hebbian learner. There are 5 meanings and 5 signals in the languages and 100 agents in the population, with one agent being replaced every generation by a new learner, who is exposed to 100 utterances from randomly picked members of the population. The average communicative accuracy score is also plotted for both types of learner, but in both cases it is calculated using a non-rational speaker (in order to demonstrate that the language itself is changing). This graph demonstrates again that Hebbian learners normally fail to reliably construct optimal languages, but adding rationality means that they reliably do. One interesting thing to note here is that there appears to be a slight delay in the increase in communicative accuracy for the rational Hebbians. This may be due to the fact that producing a random signal instead of one of a handful of homonyms may on some occasions actually reduce, rather than increase, expected communicative accuracy in the early stages of the evolution.\n",
    "\n",
    "## Summary so far: routes to communication\n",
    "\n",
    "In this course so far, we have seen three routes to getting optimal signalling off the ground:\n",
    "\n",
    "1. Biological evolution of innate singalling (under certain specific circumstances, e.g. mutual benefit)\n",
    "2. Cultural evolution of singalling in a population of learners with the right kind of learning bias\n",
    "3. Cultural evolution of signalling in a population of learners who do some rational inference about communication\n",
    "\n",
    "Which of these is it for language? Well, we know it can't be 1, because whatever your beliefs about innateness of language, we know that we don't have genes encoding specific meaning-signal mappings. \n",
    "\n",
    "The choice between 2 and 3 is not very clear. On the one hand, our investigation has revealed that the necessary learning bias to construct optimal signalling systems is similar to that revealed in experiments with children (namely, dispreferring synonyms and homonyms), but on the other hand we have suggested that such a bias is not likely to have evolved specifically for communication, which leaves it a bit of a mystery. (Of course, it may be that we're just lucky - that this bias derives from the type of lateral inhibition we see in the perceptual system and just happened to help us construct optimal signalling.)\n",
    "\n",
    "Alternatively, there is growing evidence that treating individual speakers (and hearers) as having an awareness of the communicative nature of language has a lot of explanatory potential. It just so happens it helps construct optimal signalling too.\n",
    "\n",
    "We have to leave this puzzle unresolved for now. However, we will return to the roles of learning bias and communicative interaction later in the course and show where they can have crucial and complementary roles in explaining the origins of structure in language.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
