{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Language 1, Why Simulate Language? (lecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This is a first draft of lecture notes for the Simulating Language course. It probably contains lots of typos!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some important questions\n",
    "\n",
    "Before we get started, it's worth thinking about what it is we're wanting to achieve. A good first step is to ask what the central goal of linguistics as a science actually is. There are many reasonable answers to this question, of course, and they'll differ among the many subdisciplines of linguistics. For example, a descriptive linguist might answer that the goal of linguistics is a careful and detailed account of the structure of individual languages. A historical linguist might be in the business of attempting to reconstruct languages that are no longer spoken. But for many branches of linguistics, I think that a good approximation of the ultimate goal is an answer to a **why** question: \"why is language the way it is?\".\n",
    "\n",
    "How might we go about approaching such a question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The evolutionary approach\n",
    "\n",
    "In this course, we will take an evolutionary approach to language, with both language and evolution here taken very broadly indeed. The evolutionary approach attempts to answer the why question by posing instead a **how** question. The idea is that we can only really figure out why language is the way it is if we understand how it came to be that way.\n",
    "\n",
    "This course will cover work carried out over the past 20 years or so, much of it pioneered here in Edinburgh, that tackles this how question as a way of providing a solid explanatory foundation for the science of language. A recent overview of this work, much of which we will replicate in this course, can be found in [Kirby (2017)](https://doi.org/10.3758/s13423-016-1166-7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The *processes* of language evolution\n",
    "\n",
    "When we hear the term \"evolution\" we naturally start thinking about genes and natural selection, of ancient prehistory and the survival of the fittest. This is of course part of the story, but one of the exciting things about human behaviour is that it is not determined solely by genes. (Actually, nothing is determined solely by genes. Every organism is the product of development in a particular environment. We'll return to this in a later lecture.) If we are to answer our **how** question as a route to answering the ultimate **why** question, then we need to take a much broader view of what the processes are that are involved in the evolution of language. In other words, what are the different ways the nature of language comes into being?\n",
    "\n",
    "Broadly speaking there are four different types of process that we will look at in this course, each of which has a role to play in shaping language:\n",
    "\n",
    "- Language use\n",
    "- Language learning\n",
    "- Language change (cultural evolution)\n",
    "- Language evolution (biological evolution)\n",
    "\n",
    "You'll notice immediately that terminology is letting us down a little here! I'm using \"language evolution\" both to refer to the overarching set of processes involved, and more specifically for the kind of evolution that involves changes in gene frequencies. Sorry about that! It is a source of a lot of confusion in the field. Some scholars like to use \"language evolution\" only in the narrowest sense (we might think of this as the biological evolution of the human faculty for language). Others prefer to cast the net a little wider and include both biological *and* cultural evolution. We'll see in a later lecture what I mean by cultural evolution, but for now you can think of this as the evolution of languages themselves rather that the evolution of the language faculty. Almost no-one takes the approach that I'm going with here by saying that everything from the way we speak from moment to moment (language use) to the way the human genome has evolved can be brought under the rubric \"language evolution\". However, I think for our purposes right now it's quite useful.\n",
    "\n",
    "All these processes involve change over time, although the timescales are quite different. Decisions made when choosing how to formulate an utterance happen in milliseconds, whereas biological evolution takes millenia. We can further subdivide these four processes into two groupings. The first two happen at what I will call the *individual level*. Although language use typically involves two or more people, and language learning at the very least requires a language learner and another producer of language, the processes can reasonably be studied by looking at what individuals do. We think about language use and language learning by thinking about the minds of the indivdiuals involved.\n",
    "\n",
    "Conversely, language change (or cultural evolution, if you prefer) and language evolution (or biological evolution) take place at the *population level*. These aren't really processes that are typically studied by looking at or thinking about individuals. Rather these are phenomenon that arise from the aggregate changes in populations of individuals.\n",
    "\n",
    "That said, an understanding of the population level in some sense *requires* an understanding of the individual level. After all, what is a population other than a collection of individuals? In fact, an overarching message of this course is that to uncover a truly explanatory model of language you can't rely on a study of any of these processes in isolation. This is because there are deep and important interactions between all these processes, despite the fact that they take place on different timescales.\n",
    "\n",
    "![img](img/interactions.png)\n",
    "\n",
    "Learning and use of language rely on properties of our language ready brains (that's what we use to process language in real time, or learn language in the first place). Since our language ready brains are provided by the long process of the biological evolution of our species, then there's clearly an important causal link between biological evolution and learning/use. This is the message of the biolinguistic programme championed by people like Lenneberg and Chomsky in the 1960s.\n",
    "\n",
    "Equally, the cultural evolution of language arises from the actions of a population of speakers and learners of language across time and space. Child learners and adult speakers shift and change properties of the language that is spoken. Indeed we can think of the dynamics of this cultural process as being ultimately determined by properties of the learning and processing mechanisms of these individuals. The actual universal structural properties of language that are the topic of our ultimate **why** question are the eventual product of this cultural evolutionary process.\n",
    "\n",
    "But the causal interactions do not stop there. Biological evolution by natural selection is driven by differences in fitness. If we assume (as many do) that possession of language can alter fitness, then we have to assume that the nature of that language, arising from cultural evolution, may have a causal effect on the process of biological evolution.\n",
    "\n",
    "Here then we have a cycle of causation crossing milliseconds to millenia and back again, and bridging the indivdiual and population levels of description. All to explain why language is the way it is!\n",
    "\n",
    "This looks hopelessly complicated, and it becomes clear looking at this why researchers have tended to want to simplify the picture and look solely at one process or another.\n",
    "\n",
    "In this course, I am going to show you that there is another way. We can begin to understand what these interacting processes do in general and on this basis build a modern explanatory framework for language based on evolutionary thinking. The way we're going to do that is to build **models**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a model?\n",
    "\n",
    "We tend to think of a model as a miniaturised version of a system we are interested in, whether that's a model of the Eiffel tower that sits on our bookshelf reminding us of a trip to Paris, or a wave tank in a physics laboratory that helps us engineer coastal defences.\n",
    "\n",
    "The value of having a miniature version of a system in science are, among other things, that: it is simpler than the real thing so that the effects of different sub-parts of the system can be more easily understood; it can be controlled more easily (we can try different coastal defenses against different types of waves without the huge cost of building them and waiting for the right storm); and the behaviour of the system can be more easily understood.\n",
    "\n",
    "There are problems too, however. It may be difficult to build a model for a system that's being studied. We may not know enough about how that system works, or it may appear so irreducibly complex that any simplification is impossible. If we do simplify, we may not know which parts of the real thing we can ignore, and which are crucial.\n",
    "\n",
    "Faced with these difficulties, it might appear safer to just study the real thing directly. Why build a model when we can simply observe the phenomenon we want to understand in the first place?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a model for? One answer...\n",
    "\n",
    "To understand when we might need a model it's worth thinking about the place of models in the scientific process. \n",
    "\n",
    "![img](img/scientific_cycle.png)\n",
    "\n",
    "One way to think about the actual practice of science is that we test theories about some phenomenon by working out what predictions those theories make and then testing those predictions against observations. The results of those tests may lead us to update our theories and then repeat the cycle again.\n",
    "\n",
    "In many cases this process is pretty straightforward, but in some cases it turns out that it is not at all obvious what the predictions are that a theory is making. After all, to get from theory to predictions, we need to somehow intuit what would happen in the world if that theory were true. This might be possible for simple phenomena, but it turns out to be extraordinarily hard for what have come to be called *complex systems*. These are systems where there are lots of interacting subcomponents whose aggregate behaviour is somehow \"emergent\" from local interactions. We'll turn to a simple example from linguistics now.\n",
    "\n",
    "### A simple example - explaining vowel distributions\n",
    "\n",
    "Vowels can be thought of as existing in a two dimensional space. This is how they are represented in the IPA for example:\n",
    "\n",
    "![img](img/vowel_space.png)\n",
    "\n",
    "The dimensions of this representation correspond roughly to the position of the highest point of the tongue in the mouth when the vowel is produced. Interestingly, they also map fairly straightforwardly to the first and second formants of the acoustic spectrum of the vowel sound too.\n",
    "\n",
    "Now, it turns out that if you look at the distribution of vowels in the world's languages only some patterns arise. For example, you never find a language in which the only three vowels are \"i\", \"e\", and \"y\". Specifically, the vowel space tends to be filled symmetrically. As a scientist studying language, we might spot this kind of pattern and look for an explanation. To do so, we first need a theory. A reasonable theory might be something like: **vowels tend to avoid being close to each other in order to maintain perceptual distinctiveness**.\n",
    "\n",
    "So, how do we tell if this theory is correct? It might not be immediately obvious what predictions this theory makes. And without predictions we can't test the theory against the real data. (Actually, in this case, perhaps you do think it's obvious, but let's go along with this example for now!) If the predictions a theory makes are not immediately obvious, then this is where we need a model - something like the wave tank.\n",
    "\n",
    "Well it turns out that in the 1970s, [Liljencrants and Lindblom (1972)](https://www.jstor.org/stable/411991) did just that and built a model of the vowel space, and it is similar in many ways to the wave tank model! In their paper they point out that vowels can be modelled using magnets attached to corks floating in water. If the magnets are set up to repel each other than the floating \"vowels\" will eventually organise themselves in wuch a way to maximise the distances between each other. Now, rather than get their hands wet, they were able to use what is known by physicists about how such repulsion works and predict what this model would do with given numbers of vowels. In this way, they constructed a model based on the theory that vowels maximise distinctiveness and compared this to the real cross-linguistic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a model for? An alternative answer\n",
    "\n",
    "Now, I've given a case for treating models as a bridge between theory and prediction. However, in some ways this sells the scientific process a little short in treating prediction as the only thing we're trying to do when we do science. An alternative or complementary approach sees models as tools for understanding.\n",
    "\n",
    "*\"Predictions are not the pinnacle of science.  They are useful, especially for falsifying theories.  However, predicting can’t be a model’s only purpose. ... surely the insights offered by a model are at least as important as its predictions: they help in understanding things by playing with them.\"* ([Sigmund, 1993, p. 4](https://books.google.co.uk/books/about/Games_of_Life.html?id=4G4vDwAAQBAJ&printsec=frontcover&source=kp_read_button&redir_esc=y))\n",
    "\n",
    "A classic example of this kind of model is the ludicrously simple and abstract model of a kind of artificial life called, appropriately, the Game of Life. It was invented by [John Conway](https://web.archive.org/web/20090603015231/http://ddi.cs.uni-potsdam.de/HyFISCH/Produzieren/lis_projekt/proj_gamelife/ConwayScientificAmerican.htm) in 1970 and there are many implementations of it you can [play with in your web browswer](https://www.bjelic.net/game-of-life/game2.html). In this model, there is a square grid of \"cells\". Every cell has 8 neighbours that surround it. Cells can either be alive or dead. Each \"round\" of the game, the cells are updated such that some die and some come alive. The update works according to the following very simple rules:\n",
    "\n",
    "- Any dead cell with 3 live neighbours becomes alive.\n",
    "- Any live cell with 2 or 3 live neighbours stays alive.\n",
    "- Otherwise the cell dies.\n",
    "\n",
    "A simple sequence in the game of life from a particular starting position is shown here:\n",
    "\n",
    "![img](img/life.png)\n",
    "\n",
    "This a very short sequence of turns in the Game of Life. However, the remarkable thing about this incredibly simple \"game\" is that it can lead to enormously complex behaviours depending solely on the initial configuration of cells. In fact, just five living cells in the right organisation can lead to patterns that last thousands of rounds of the game, creating hugely elaborate and evolving structures.\n",
    "\n",
    "This tells us something very important about the relationship between simplicity and complexity: complex systems can emerge from very simple interacting components!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplicity and complexity in models\n",
    "\n",
    "This talk of simplicity and complexity (which, you'll note, I have yet to define - more on that later in the course) raises an important methodological point. I have said that models are simplified versions of theories that allow us insight and to generate predictions, but how do we decide how close to reality a model should be? It's not entirely obvious where a model should sit on the spectrum between leaving nothing out and being as close as possible to the real thing, or leaving lots out and being as simple as possible.\n",
    "\n",
    "In practice, a lot of the art of good modelling is finding the right spot on this spectrum. I tend to think that simpler is better up to a point, because what will we learn by building something as complex as the real thing? Simpler models are easier to build, easier to use, and are in my experience, likely to deliver better insights. But there are limits - you can't miss out important parts of the theory you are testing. Equally you should include as little extra that isn't in your theory that you can, because otherwise you won't know if the predictions you get actually correspond to the theory you're testing.\n",
    "\n",
    "Anyway, you don't need to take my word for it. Einstein is said to have commented: [\"everything should be as simple as possible, but not simpler.\"](https://quoteinvestigator.com/2011/05/13/einstein-simple/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use computers for modelling language?\n",
    "\n",
    "We've seen that you can build physical models, or models based on mathematics borrowed from physics, but clearly this course is about using computers to build models. Simulations are basically models that can be run on computers to generate predictions or insights. The Game of Life was originally developed using pieces of paper on the floor of a common room in a university department, but nowadays we explore the insights of that model by simulating it in a computer.\n",
    "\n",
    "There are several reasons why computers can be good for modelling. Often a physical model simply can't be built that matches the theory you are investigating, or a purely mathematical (pencil and paper) model is too difficult (or indeed impossible) to construct. In these cases, the computer can step in and provide us an alomst unlimited potential for model building.\n",
    "\n",
    "In particular, we tend to find that mathematical models become difficult to construct in problems that involve dynamic interactions. Notice that these are *precisely* the kinds of things that we're saying are responsible for the evolution of language! For example, if we want to understand how a child's knowledge changes as she responds to hearing thousands of words, or what happens when people interact in groups over thousands of years, or when communicating organisms evolve over millenia - in these cases, computational modelling is the solution.\n",
    "\n",
    "Computers are absolutely perfect for constructing models with very many simple interacting components. Whereas we may balk at the thought of tracking hundreds of thousands of cells in the game of life over hundreds of thousands of generations, this is really trivial for a computer. The program to run the game of life is not much more complicated than the description of its rules, and - crucially - does not need to get more complicated simply because it is run for longer or for a greater number of cells.\n",
    "\n",
    "The idea that simulation opens up our understanding of systems with many interacting elements has proved particularly valuable in allowing us to build the fundamentally evolutionary approach to understanding language that we've been aiming at.\n",
    "\n",
    "In this course, we will be building and playing with models to tackle questions like:\n",
    "\n",
    "- how do communicating species evolve?\n",
    "- how are communication systems shaped by cultural evolution?\n",
    "- where do grammatical generalisations come from?\n",
    "- what do we mean when we say language is innate?\n",
    "\n",
    "Despite the apparent magnitude of these questions, the main message I want to get across is how relatively straightforward it is to actually build these models. Even if you have never programmed a computer before, if you work through these lectures and labs carefully, you should be able to replicate some of the cutting edge results in the field of evolutionary linguistics and see how we can answer these kinds of questions without relying on purely rhetorical argument, and instead demonstrate our answers using working simulations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
