{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Language 13, Iterated Learning (lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation we'll build in this notebook explores the cultural evolution of a signalling system in a population of agents. In particular, we’ll look at the effects on communicative accuracy of:\n",
    "- different learning biases (weight update rules),\n",
    "- different ways of communicating,\n",
    "- different populations models\n",
    "\n",
    "There's a lot in this lab, so it's probably worth having a play with the simulation runs first before going back and understanding the code. However, make sure you understand what the new parameters do first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll most of the code from the last lab. (We're going to replace the `learn` and `pop_produce` functions later on, so we're leaving them out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf')\n",
    "\n",
    "def wta(items):\n",
    "    maxweight = max(items)\n",
    "    candidates = []\n",
    "    for i in range(len(items)):\n",
    "        if items[i] == maxweight:\n",
    "            candidates.append(i)\n",
    "    return random.choice(candidates)\n",
    "\n",
    "def reception_weights(system, signal):\n",
    "    weights = []\n",
    "    for row in system:\n",
    "        weights.append(row[signal])\n",
    "    return weights\n",
    "\n",
    "def communicate(speaker_system, hearer_system, meaning):\n",
    "    speaker_signal = wta(speaker_system[meaning])\n",
    "    hearer_meaning = wta(reception_weights(hearer_system, speaker_signal))\n",
    "    if meaning == hearer_meaning: \n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "def train(system, ms_pair_list):\n",
    "    for pair in ms_pair_list:\n",
    "        learn(system, pair[0], pair[1])\n",
    "\n",
    "def pop_learn(population, data, no_learning_episodes):\n",
    "    for n in range(no_learning_episodes):\n",
    "        ms_pair = random.choice(data)\n",
    "        learn(random.choice(population), ms_pair[0], ms_pair[1])\n",
    "\n",
    "def ca_monte_pop(population, trials):\n",
    "    total = 0.\n",
    "    for n in range(trials):\n",
    "        speaker = random.choice(population)\n",
    "        hearer = random.choice(population)\n",
    "        total += communicate(speaker, hearer, random.randrange(len(speaker)))\n",
    "    return total / trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new part of our code starts with a set of parameter declarations; most of their meanings should all be straightforward by now. Note that the interactions parameter has two purposes in this simulation:\n",
    "- to specify the number of utterances produced to create the data.\n",
    "- to specify the number of times the data is randomly sampled in training.\n",
    "\n",
    "We've added a parameter to control how the population is updated through iterated learning (see below), and one that specifies the type of the initial language. We've also added two slightly mysterious parameters. These both can be either `True` or `False`. If a variable takes one of these forms it can be used whenever you use an `if` in python. For example, this should print \"yes, it is true!\" out on the screen:\n",
    "\n",
    "```python\n",
    "x = True\n",
    "if x:\n",
    "    print('yes, it is true!')\n",
    "```\n",
    "\n",
    "`inhibition` controls whether learning involves \"lateral inhibition\", which we'll explain below. `communication` controls whether the sender tries to avoid signals that would be communicatively unsuccessful. We'll also see how this is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanings = 5                     # number of meanings\n",
    "signals = 5                      # number of signals\n",
    "interactions = 100               # both the number of utterances produced and the number\n",
    "                                 # of times this set is randomly sampled for training.\n",
    "size = 100                       # size of population\n",
    "method = 'replacement'           # method of population update\n",
    "initial_language_type = 'random' # either 'optimal' or 'random'\n",
    "rule = [1, 0, 0, 0]              # learning rule (alpha, beta, gamma, delta)\n",
    "inhibition = False               # apply lateral inhibition (can be True or False)\n",
    "communication = False            # speaker tries to avoid ambiguity (can be True or False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `new_agent` below creates a new agent. The weights in this agent’s network depend on the parameter `initial_language_type`. If this parameter is set to `random` (or in fact to anything other than `optimal`), every cell in the new agent’s signalling matrix is set initially to zero. If the `initial_language_type` parameter is set to `optimal`, then the weights are configured such that the agent’s initial weights ensure it signals optimally (`m1` is conveyed using `s1`, `m2` is conveyed using `s2`, etc). The function `new_population` then uses the `new_agent` function to create a population of new agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_agent(initial_language_type):\n",
    "    system = []\n",
    "    for row_n in range(meanings):\n",
    "        row = []\n",
    "        for column_n in range(signals):\n",
    "            if initial_language_type == 'optimal' and row_n == column_n:\n",
    "                row.append(1)\n",
    "            else:\n",
    "                row.append(0)\n",
    "        system.append(row)\n",
    "    return system\n",
    "\n",
    "def new_population(size, initial_language_type):\n",
    "    population = []\n",
    "    for i in range(size):\n",
    "        population.append(new_agent(initial_language_type))\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lateral inhibition in learning\n",
    "\n",
    "This is a slightly more complicated learning function compared to what we had before. Now, instead of just counting the number of times an agent sees a meaning with a signal, the association weights between all the (wrong) signals that are associated with that meaning can be reduced, and all the (wrong) meanings that are associated with that signal can be reduced. This is called \"lateral inhibition\" in that all the associations sideways along the rows and columns are inhibited each time a pair is strengthened. If `inhibition` is `False` then `learn` works just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(system, meaning, signal):\n",
    "    system[meaning][signal] += 1\n",
    "    if inhibition:\n",
    "        for m in range(len(system)):\n",
    "            for s in range(len(system[m])):\n",
    "                if (m != meaning and s == signal) or (m == meaning and s != signal):\n",
    "                    system[m][s] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communicatively rational speakers\n",
    "\n",
    "So far in this course, speakers haven't \"tried\" to be communicative. They have simply produced what their signalling matrix told them to. But a more rational speaker would not blindly produce a signal if it is going to be misunderstood. How could a speaker know that they are going to be misunderstood if they don't know what the hearer has in their signalling matrix? One way is to assume that the hearer is like them and imagine what *they* would understand if they heard a given signal. This what the following code does. If `communication` is `True` then the speaker checks whether the signal they are about to produce would allow them themselves to understand the right meaning. If it doesn't they just try a random other signal instead. If `communication` is `False`, then it works exactly as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce(speaker, meaning):\n",
    "    signal = wta(speaker[meaning])\n",
    "    if communication:\n",
    "        speaker_meaning = wta(reception_weights(speaker, signal))\n",
    "        if (meaning != speaker_meaning):\n",
    "            signal = random.randrange(len(speaker[0]))\n",
    "    return signal\n",
    "\n",
    "def pop_produce(population, no_productions):\n",
    "    ms_pairs = []\n",
    "    for n in range(no_productions):\n",
    "        speaker = random.choice(population)     \n",
    "        meaning = random.randrange(len(speaker))\n",
    "        signal = produce(speaker, meaning)\n",
    "        ms_pairs.append([meaning, signal])\n",
    "    return ms_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Try out the `produce` function with different speaker matrices and meanings to make sure it behaves as you would expect when you use a matrix that has homonymy in it when you change the `communication` parameter. (Hint: even when the speaker is being communicatively helpful, they may still use an unhelpful signal by chance, so you might have to run `produce` thousands of times and count the results to see the difference in practice. If you sit down with a piece of paper and a pen, you could even come up with a prediction of exactly how much better the communicatively rational speaker should be for a given signalling matrix!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(generations, mc_trials, report_every):\n",
    "    population = new_population(size, initial_language_type)\n",
    "    data_accumulator = []\n",
    "    for i in range(generations + 1):\n",
    "        if (i % report_every == 0):\n",
    "            data_accumulator.append(ca_monte_pop(population, mc_trials))\n",
    "        data = pop_produce(population, interactions)\n",
    "        if method == 'chain':\n",
    "            population = new_population(size, 'random')\n",
    "            pop_learn(population, data, interactions)\n",
    "        if method == 'replacement':\n",
    "            population = population[1:]\n",
    "            learner = new_agent('random')\n",
    "            pop_learn([learner], data, interactions)\n",
    "            population.append(learner)\n",
    "        if method == 'closed':\n",
    "            pop_learn(population, data, interactions)\n",
    "    return [population, data_accumulator]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation function runs the simulation. It takes three parameters, as follows:\n",
    "- `generations`: the number of generations in the simulation\n",
    "- `mc_trials`: the number of trials used to calculate communicative accuracy \n",
    "- `report_every`: the frequency with which data points (for printing in a graph) are returned\n",
    "\n",
    "It then runs through the following steps:\n",
    "1. Initialise the population\n",
    "2. For each generation:\n",
    "    1. Evaluate the population’s communicative accuracy\n",
    "    2. Produce some data\n",
    "    3. Update the population (by adding new agents)\n",
    "    4. Get (some of) the new population to learn from the data produced in 2A.\n",
    "3. Output the final state of the population, and the list of communicative accuracy scores\n",
    "\n",
    "The parameter `method` defines exactly how the population is updated, based on the scheme outlined by Mesoudi & Whiten:\n",
    "- `chain`: create a completely new population\n",
    "- `replacement`: remove one agent from the population, and replace with a new agent\n",
    "- `closed`: do not change the population at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two things to note about the Python code in this function.\n",
    "\n",
    "### Review: slicing a list\n",
    "\n",
    "The slice `[start : end]` operator allows us to take a slice of sequential elements between start and end from a list.\n",
    "As usual in Python, the sequence extracts starts at start, and continues up to, but not including, end. Either the start or end (or both) indexes can be omitted, in which case the start or end of the list is assumed, respectively.\n",
    "\n",
    "For example, try the following:\n",
    "\n",
    "```python\n",
    "x = ['a', 'b', 'c', 'd']\n",
    "print(x[1:])\n",
    "print(x[:3])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modulus (remainder)\n",
    "\n",
    "The `x % y` operator returns the remainder of the division of x by y.\n",
    "\n",
    "For example, `7 % 3` gives us `1`, `11 % 4` gives us `3`, and `10 % 2` gives us `0`.\n",
    "\n",
    "In the `simulation` function, the modulus operator is used to decide whether or not to calculate the value of `ca_monte_pop` and output it for the graphs. Can you see how it works? (We do this because calculating the communicative accuracy actually takes quite a bit of time, so we don't want to slow it down too much!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Everyone should try questions 1-4. Question 5 is more open-ended, and needn’t involve coding (but could).\n",
    "\n",
    "1. Run the simulation for 500 generations, with 1000 mc_trials per generation, outputting communicative accuracy every 10 generations. Plot the values on a graph. (Hint: be careful with your x-axis. Are you sure you understand what it means!)\n",
    "2. Experiment with turning on and off lateral inhibition and communicatively rational speakers (by changing the `inhibition` and `communication` parameters to `True`). Which combinations construct perfect construct perfect communicative systems from random languages?\n",
    "3. Change the population update method to ‘chain’, and re-run the simulation. What happens? Why? Increase the number of interactions by a factor of 100, and reduce the number of generations by a factor of 10. What happens now?\n",
    "4. Experiment with the ‘closed’ method as well. What difference does the update method make to the way the simulation works?\n",
    "5. In previous worksheets you have had the opportunity to write and play with code which models genetic transmission, spatial organisation, and so on. How would you fit these things in to this iterated learning model? Why might that be an interesting thing to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
